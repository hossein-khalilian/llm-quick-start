{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ad97fc-80c5-4d08-8d33-833076a3c9f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d6b236-3d08-42fb-a163-ba3f76edb1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1985afc-1a6a-41ab-8367-1f4899e39c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1b82e-50a6-484c-b90c-82255fb1f41c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee05361-2315-4bff-b963-a29559655afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-CCMoyvub6FNPiKTSD7s1fq\n"
     ]
    }
   ],
   "source": [
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    \n",
    "    return result.id\n",
    "\n",
    "# Replace with your own file path or URL\n",
    "file_id = create_file(client, \"https://cdn.openai.com/API/docs/deep_research_blog.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14105e9-a4ad-4787-a723-3cbb8c939509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_6829770cd6108191b450ce28bc6b7a20\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"knowledge_base\"\n",
    ")\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f646d9-ff39-4663-9e71-8f1bc8043492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-CCMoyvub6FNPiKTSD7s1fq', created_at=1747547994, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_6829770cd6108191b450ce28bc6b7a20', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3201d8e-d67e-465e-85c2-e7150e22d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-CCMoyvub6FNPiKTSD7s1fq', created_at=1747547917, last_error=None, object='vector_store.file', status='completed', usage_bytes=66539, vector_store_id='vs_6829770cd6108191b450ce28bc6b7a20', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-CCMoyvub6FNPiKTSD7s1fq', last_id='file-CCMoyvub6FNPiKTSD7s1fq')\n"
     ]
    }
   ],
   "source": [
    "result = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c1073e-ce07-4caf-9881-2e8fa18dd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while result.data[0].status != \"completed\":\n",
    "    print(\"Waiting for completion...\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74250a49-d466-4b1e-b67f-8095a29f854d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# file search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde8dc64-6439-4b52-83a8-85930026ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"What is deep research by OpenAI?\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store.id],\n",
    "        # \"max_num_results\": 2\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf09661-53ea-42cc-a898-620b66258746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_6829778e05788191bdd53a08b54a21f003714efe75539749',\n",
       " 'created_at': 1747548046.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'response',\n",
       " 'output': [{'id': 'fs_6829778ea5848191a1daa6b551d263b003714efe75539749',\n",
       "   'queries': ['deep research by OpenAI'],\n",
       "   'status': 'completed',\n",
       "   'type': 'file_search_call',\n",
       "   'results': None},\n",
       "  {'id': 'msg_6829779143a48191adfc0ecccac4b82103714efe75539749',\n",
       "   'content': [{'annotations': [{'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 644,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 922,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 922,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 1215,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 1215,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 1379,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 1379,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'},\n",
       "      {'file_id': 'file-CCMoyvub6FNPiKTSD7s1fq',\n",
       "       'index': 1595,\n",
       "       'type': 'file_citation',\n",
       "       'filename': 'deep_research_blog.pdf'}],\n",
       "     'text': \"**Deep Research** is a newly launched capability by OpenAI, designed to perform comprehensive multi-step research tasks. Here are the key features and functionalities:\\n\\n1. **Agentic Capability**: Deep Research utilizes reasoning to synthesize vast amounts of information from the internet, effectively conducting complex research tasks autonomously. Users provide a prompt, and Deep Research analyzes and synthesizes relevant online sources to produce detailed reports.\\n\\n2. **Efficiency**: This tool can complete tasks in a matter of minutes, which would typically take a human several hours, thereby dramatically increasing research efficiency.\\n\\n3. **Training Approach**: The model behind Deep Research leverages reinforcement learning methods, allowing it to browse and use Python tools for tasks. This training enables it to adaptively gather and reason about real-time information as it completes its research findings.\\n\\n4. **Applications**: It is particularly beneficial for fields that require intensive knowledge work, such as finance, science, policy, and engineering. Users can request complex analyses or personalized recommendations, and outputs provide clear citations and documentation for verification.\\n\\n5. **Output Format**: Once research is completed, outputs are structured as reports, often complemented with visual aids like graphs and summaries of steps taken.\\n\\n6. **Limitations**: While Deep Research has advanced capabilities, it may still produce errors or misunderstand nuanced information. The system is continuously being refined to overcome its early-stage limitations.\\n\\nIn summary, OpenAI's Deep Research aims to revolutionize how users conduct complex research tasks, making it quicker and more efficient, while also ensuring rigorous output documentation.\",\n",
       "     'type': 'output_text'}],\n",
       "   'role': 'assistant',\n",
       "   'status': 'completed',\n",
       "   'type': 'message'}],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [{'type': 'file_search',\n",
       "   'vector_store_ids': ['vs_6829770cd6108191b450ce28bc6b7a20'],\n",
       "   'filters': None,\n",
       "   'max_num_results': 20,\n",
       "   'ranking_options': {'ranker': 'auto', 'score_threshold': 0.0}}],\n",
       " 'top_p': 1.0,\n",
       " 'max_output_tokens': None,\n",
       " 'previous_response_id': None,\n",
       " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': {'format': {'type': 'text'}},\n",
       " 'truncation': 'disabled',\n",
       " 'usage': {'input_tokens': 17407,\n",
       "  'input_tokens_details': {'cached_tokens': 0},\n",
       "  'output_tokens': 385,\n",
       "  'output_tokens_details': {'reasoning_tokens': 0},\n",
       "  'total_tokens': 17792},\n",
       " 'user': None,\n",
       " 'store': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
