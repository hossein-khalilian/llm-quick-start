{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4a14f9-45e4-4710-b07b-7ec1a89a920a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:40:28.092388Z",
     "iopub.status.busy": "2025-05-20T09:40:28.092075Z",
     "iopub.status.idle": "2025-05-20T09:40:28.096521Z",
     "shell.execute_reply": "2025-05-20T09:40:28.095888Z",
     "shell.execute_reply.started": "2025-05-20T09:40:28.092357Z"
    },
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a02b1ad-b523-4a5f-be82-aa2a8a1178c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:49:24.408218Z",
     "iopub.status.busy": "2025-05-21T14:49:24.407541Z",
     "iopub.status.idle": "2025-05-21T14:49:25.173697Z",
     "shell.execute_reply": "2025-05-21T14:49:25.172862Z",
     "shell.execute_reply.started": "2025-05-21T14:49:24.408179Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url=\"http://host.docker.internal:11434\"\n",
    "model_name = \"gemma3:27b\"\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(\n",
    "    model=model_name,\n",
    "    base_url=base_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdb585-76d3-4d58-8fc3-154a5980c211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a530f0ab-b00c-488d-86e3-615bd17b15d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:49:34.304074Z",
     "iopub.status.busy": "2025-05-21T14:49:34.303818Z",
     "iopub.status.idle": "2025-05-21T14:49:34.310077Z",
     "shell.execute_reply": "2025-05-21T14:49:34.309335Z",
     "shell.execute_reply.started": "2025-05-21T14:49:34.304053Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "    id: str\n",
    "    type: str\n",
    "    \n",
    "\n",
    "\n",
    "def invoke_tool(\n",
    "    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None\n",
    "):\n",
    "    \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "    Args:\n",
    "        tool_call_request: a dict that contains the keys name and arguments.\n",
    "            The name must match the name of a tool that exists.\n",
    "            The arguments are the arguments to that tool.\n",
    "        config: This is configuration information that LangChain uses that contains\n",
    "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "    Returns:\n",
    "        output from the requested tool\n",
    "    \"\"\"\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    \n",
    "    return requested_tool.invoke(tool_call_request[\"args\"], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422a4413-2e38-4122-b3b0-4fb852f42afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T10:20:37.205104Z",
     "iopub.status.busy": "2025-05-24T10:20:37.202919Z",
     "iopub.status.idle": "2025-05-24T10:20:37.230786Z",
     "shell.execute_reply": "2025-05-24T10:20:37.229499Z",
     "shell.execute_reply.started": "2025-05-24T10:20:37.205025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Retrieve useful and important documents based on the input query.\\n\\nThis function is intended to interact with a retrieval system, such as a vector store,\\nkeyword-based search, or document index, to return relevant content.', 'properties': {'input_query': {'title': 'Input Query', 'type': 'string'}}, 'required': ['input_query'], 'title': 'retrieve', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"Add two numbers.\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve(input_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve useful and important documents based on the input query.\n",
    "\n",
    "    This function is intended to interact with a retrieval system, such as a vector store,\n",
    "    keyword-based search, or document index, to return relevant content.\n",
    "    \"\"\"\n",
    "    return input_query\n",
    "\n",
    "tools = [retrieve]\n",
    "\n",
    "print(retrieve.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56105cb6-5ca6-4cf1-851a-ca7edc707bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T15:10:05.484733Z",
     "iopub.status.busy": "2025-05-21T15:10:05.484371Z",
     "iopub.status.idle": "2025-05-21T15:10:05.490480Z",
     "shell.execute_reply": "2025-05-21T15:10:05.489638Z",
     "shell.execute_reply.started": "2025-05-21T15:10:05.484703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve(input_query: str) -> str - Retrieve useful and important documents based on the input query.\n",
      "\n",
      "This function is intended to interact with a retrieval system, such as a vector store,\n",
      "keyword-based search, or document index, to return relevant content.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14a1d8-86ca-4788-8538-21d3ae6bf50a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# single tool calling at a time (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a561fe3-f728-4394-8873-614e17ff1683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T15:10:06.546184Z",
     "iopub.status.busy": "2025-05-21T15:10:06.545902Z",
     "iopub.status.idle": "2025-05-21T15:10:06.550870Z",
     "shell.execute_reply": "2025-05-21T15:10:06.550248Z",
     "shell.execute_reply.started": "2025-05-21T15:10:06.546161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have access to functions. If you decide to invoke any of the function(s),\n",
      "you MUST put it in the format of\n",
      "{{\n",
      "    \"name\": function name, \n",
      "    \"args\": dictionary of argument name and its value,\n",
      "}}\n",
      "\n",
      "You SHOULD NOT include any other text in the response if you call a function\n",
      "retrieve(input_query: str) -> str - Retrieve useful and important documents based on the input query.\n",
      "\n",
      "This function is intended to interact with a retrieval system, such as a vector store,\n",
      "keyword-based search, or document index, to return relevant content.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"\\\n",
    "You have access to functions. If you decide to invoke any of the function(s),\n",
    "you MUST put it in the format of\n",
    "{{{{\n",
    "    \"name\": function name, \n",
    "    \"args\": dictionary of argument name and its value,\n",
    "}}}}\n",
    "\n",
    "You SHOULD NOT include any other text in the response if you call a function\n",
    "{rendered_tools}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")\n",
    "\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a1020bf-dd55-431d-a990-767137b86e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T15:10:33.902107Z",
     "iopub.status.busy": "2025-05-21T15:10:33.901822Z",
     "iopub.status.idle": "2025-05-21T15:10:35.418703Z",
     "shell.execute_reply": "2025-05-21T15:10:35.416690Z",
     "shell.execute_reply.started": "2025-05-21T15:10:33.902084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'retrieve', 'args': {'input_query': 'what is task decomposition?'}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOutputParser()\n",
    "# chain.invoke({\"input\": \"what's thirteen times 4 and 12 plus 7\"})\n",
    "chain.invoke({\"input\": \"hi there how are you? can you tell me what is task decomposition \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05dc20dc-8981-4112-a709-33d8e5664e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:55:07.142519Z",
     "iopub.status.busy": "2025-05-21T14:55:07.142244Z",
     "iopub.status.idle": "2025-05-21T14:55:07.149037Z",
     "shell.execute_reply": "2025-05-21T14:55:07.148300Z",
     "shell.execute_reply.started": "2025-05-21T14:55:07.142497Z"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "class JsonOrRawParser(JsonOutputParser):\n",
    "    def invoke(self, input, config=None):\n",
    "        try:\n",
    "            input.tool_calls = super().invoke(input) | {\"id\": str(uuid.uuid4()), \"type\": \"tool_call\"}\n",
    "            input.content = \"\"\n",
    "            return input\n",
    "            \n",
    "        except Exception as e:\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9521c63-69aa-487f-956c-db1a17580007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:55:09.343219Z",
     "iopub.status.busy": "2025-05-21T14:55:09.342462Z",
     "iopub.status.idle": "2025-05-21T14:55:10.719699Z",
     "shell.execute_reply": "2025-05-21T14:55:10.718293Z",
     "shell.execute_reply.started": "2025-05-21T14:55:09.343142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gemma3:27b', 'created_at': '2025-05-21T14:55:10.428253309Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1151981790, 'load_duration': 98748169, 'prompt_eval_count': 124, 'prompt_eval_duration': 40847117, 'eval_count': 41, 'eval_duration': 1010048795, 'model_name': 'gemma3:27b'}, id='run--42303f37-b6c8-4707-b6d6-f0375952234e-0', tool_calls={'name': 'add', 'args': {'x': 2, 'y': 3}, 'id': '417cfc70-be50-4637-8f7f-50deba18642d', 'type': 'tool_call'}, usage_metadata={'input_tokens': 124, 'output_tokens': 41, 'total_tokens': 165})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOrRawParser()\n",
    "result = chain.invoke({\"input\": \"2+3\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9846f584-3ead-4e23-a2e2-ade6ac53dfc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:55:13.284478Z",
     "iopub.status.busy": "2025-05-21T14:55:13.284209Z",
     "iopub.status.idle": "2025-05-21T14:55:13.941717Z",
     "shell.execute_reply": "2025-05-21T14:55:13.939404Z",
     "shell.execute_reply.started": "2025-05-21T14:55:13.284456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='hi there! how can i help you today?\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'model': 'gemma3:27b', 'created_at': '2025-05-21T14:55:13.643496814Z', 'done': True, 'done_reason': 'stop', 'total_duration': 430958687, 'load_duration': 98520932, 'prompt_eval_count': 122, 'prompt_eval_duration': 35588876, 'eval_count': 12, 'eval_duration': 294855729, 'model_name': 'gemma3:27b'}, id='run--c381627a-fa7a-4a4d-9d69-c3d36fed6a1a-0', usage_metadata={'input_tokens': 122, 'output_tokens': 12, 'total_tokens': 134})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOrRawParser()\n",
    "chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "073c84cf-52a5-4161-8950-ce1d4ca077cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:55:15.399931Z",
     "iopub.status.busy": "2025-05-21T14:55:15.399681Z",
     "iopub.status.idle": "2025-05-21T14:55:16.911355Z",
     "shell.execute_reply": "2025-05-21T14:55:16.910285Z",
     "shell.execute_reply.started": "2025-05-21T14:55:15.399909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'args': {'a': 13, 'b': 4.14137281}, 'output': 53.83784653}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)\n",
    ")\n",
    "chain.invoke({\"input\": \"what's thirteen times 4.14137281\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6150b6-e95e-43da-ac1e-322ceaf40bab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# multi-tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59837f9-5fb1-48fd-bc83-3a03c283d935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:49:52.121034Z",
     "iopub.status.busy": "2025-05-21T14:49:52.119778Z",
     "iopub.status.idle": "2025-05-21T14:49:52.132380Z",
     "shell.execute_reply": "2025-05-21T14:49:52.130946Z",
     "shell.execute_reply.started": "2025-05-21T14:49:52.120959Z"
    }
   },
   "outputs": [],
   "source": [
    "# [\n",
    "#   {{{{\n",
    "#     \"name\": \"tool_name\",\n",
    "#     \"arguments\": {{{{\n",
    "#       \"x\": value1,\n",
    "#       \"y\": value2\n",
    "#     }}}}\n",
    "#   }}}},\n",
    "#   ...\n",
    "# ]\n",
    "\n",
    "# [{{{{\"name\": function name, \"arguments\": }}}}, {{{{...}}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfc9420-1546-42c2-9c19-8dba216cfdfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:49:55.154310Z",
     "iopub.status.busy": "2025-05-21T14:49:55.152984Z",
     "iopub.status.idle": "2025-05-21T14:49:55.161270Z",
     "shell.execute_reply": "2025-05-21T14:49:55.160591Z",
     "shell.execute_reply.started": "2025-05-21T14:49:55.154238Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\\\n",
    "You have access to functions. If you decide to invoke any of the function(s),\n",
    "you MUST put it in the format of\n",
    "\n",
    "[\n",
    "  {{{{\n",
    "    \"name\": \"tool_name\",\n",
    "    \"arguments\": dictionary of argument name and its value\n",
    "  }}}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "You SHOULD NOT include any other text in the response if you call a function.\n",
    "{rendered_tools}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884037fa-aac9-4f64-9bbd-2ec1defbc04c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:50:07.513607Z",
     "iopub.status.busy": "2025-05-21T14:50:07.512842Z",
     "iopub.status.idle": "2025-05-21T14:50:07.532562Z",
     "shell.execute_reply": "2025-05-21T14:50:07.531277Z",
     "shell.execute_reply.started": "2025-05-21T14:50:07.513542Z"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "class JsonOrRawParser(JsonOutputParser):\n",
    "    def invoke(self, input, config=None):\n",
    "        try:\n",
    "            tool_calls = super().invoke(input)\n",
    "            tool_calls = [tool_call | {\"id\": str(uuid.uuid4()), \"type\": \"tool_call\"} for tool_call in tool_calls]\n",
    "            input.tool_calls = tool_calls\n",
    "            input.content = \"\"\n",
    "            \n",
    "            return input\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c79b4c-76c9-4441-a28a-149ba6803645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:50:07.853959Z",
     "iopub.status.busy": "2025-05-21T14:50:07.853689Z",
     "iopub.status.idle": "2025-05-21T14:50:15.938256Z",
     "shell.execute_reply": "2025-05-21T14:50:15.936008Z",
     "shell.execute_reply.started": "2025-05-21T14:50:07.853938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gemma3:27b', 'created_at': '2025-05-21T14:50:15.644604347Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7642959938, 'load_duration': 5954346745, 'prompt_eval_count': 139, 'prompt_eval_duration': 342502896, 'eval_count': 52, 'eval_duration': 1282938783, 'model_name': 'gemma3:27b'}, id='run--88737e0f-018a-486e-862e-49474440e357-0', tool_calls=[{'name': 'multiply', 'arguments': {'a': 13.0, 'b': 4.0}, 'id': 'dbfc737e-8135-43a5-bf51-3c5a52535454', 'type': 'tool_call'}], usage_metadata={'input_tokens': 139, 'output_tokens': 52, 'total_tokens': 191})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | JsonOrRawParser()\n",
    "chain.invoke({\"input\": \"what's thirteen times 4 \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2349e1b-f116-4ac5-813a-0e9254cb49ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:51:36.363026Z",
     "iopub.status.busy": "2025-05-21T14:51:36.362764Z",
     "iopub.status.idle": "2025-05-21T14:51:36.370553Z",
     "shell.execute_reply": "2025-05-21T14:51:36.369642Z",
     "shell.execute_reply.started": "2025-05-21T14:51:36.363004Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union, Any\n",
    "\n",
    "def run_tool_calls(tool_calls: list[ToolCallRequest]):\n",
    "    results = []\n",
    "    for call in tool_calls:\n",
    "        result = invoke_tool(call)\n",
    "        results.append({\n",
    "            \"name\": call[\"name\"],\n",
    "            \"arguments\": call[\"arguments\"],\n",
    "            \"output\": result\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def maybe_invoke_tool(response: Union[str, Any]):\n",
    "    try:\n",
    "        text = response.content if hasattr(response, \"content\") else response\n",
    "        parsed = json.loads(text)\n",
    "        print(parsed)\n",
    "        if isinstance(parsed, dict) and \"name\" in parsed and \"arguments\" in parsed:\n",
    "            # Single tool call\n",
    "            output = invoke_tool(parsed)\n",
    "            return {\n",
    "                \"name\": parsed[\"name\"],\n",
    "                \"arguments\": parsed[\"arguments\"],\n",
    "                \"output\": output\n",
    "            }\n",
    "        else:\n",
    "            # Not a tool call - just return text\n",
    "            return {\"output\": text}\n",
    "    except Exception:\n",
    "        # Parsing failed, return raw response\n",
    "        text = response.content if hasattr(response, \"content\") else response\n",
    "        return {\"output\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b20fcb-f8b1-419b-919a-fc25846ece01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:51:36.990494Z",
     "iopub.status.busy": "2025-05-21T14:51:36.988751Z",
     "iopub.status.idle": "2025-05-21T14:51:36.994888Z",
     "shell.execute_reply": "2025-05-21T14:51:36.994022Z",
     "shell.execute_reply.started": "2025-05-21T14:51:36.990465Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = prompt | model | RunnableLambda(maybe_invoke_tool) | RunnableLambda(run_tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "317d29d6-6552-4ddc-bcb3-27c10db10bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T14:51:44.226144Z",
     "iopub.status.busy": "2025-05-21T14:51:44.224787Z",
     "iopub.status.idle": "2025-05-21T14:51:47.399678Z",
     "shell.execute_reply": "2025-05-21T14:51:47.394212Z",
     "shell.execute_reply.started": "2025-05-21T14:51:44.226070Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is 234 * 3 and what is 293 + 98\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/base.py:4757\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4743\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4744\u001b[39m \n\u001b[32m   4745\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4754\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4755\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4758\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4759\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4760\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4761\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4762\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4763\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4764\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/base.py:1930\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1926\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1928\u001b[39m         output = cast(\n\u001b[32m   1929\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1930\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1933\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1935\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1936\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1937\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1938\u001b[39m         )\n\u001b[32m   1939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1940\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/base.py:4615\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4613\u001b[39m                 output = chunk\n\u001b[32m   4614\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4615\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4616\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4617\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4618\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4619\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun_tool_calls\u001b[39m\u001b[34m(tool_calls)\u001b[39m\n\u001b[32m      4\u001b[39m results = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m tool_calls:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     result = \u001b[43minvoke_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     results.append({\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m\"\u001b[39m: call[\u001b[33m\"\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: result\n\u001b[32m     11\u001b[39m     })\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36minvoke_tool\u001b[39m\u001b[34m(tool_call_request, config)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A function that we can use the perform a tool invocation.\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33;03m    output from the requested tool\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m tool_name_to_tool = {tool.name: tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools}\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m name = \u001b[43mtool_call_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     30\u001b[39m requested_tool = tool_name_to_tool[name]\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m requested_tool.invoke(tool_call_request[\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m], config=config)\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is 234 * 3 and what is 293 + 98\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8f06a-c108-4ef5-b8f3-8992b0157475",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# add summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "148963e4-d07b-4f71-89cf-17eac62ff5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:04:02.797279Z",
     "iopub.status.busy": "2025-05-21T08:04:02.797006Z",
     "iopub.status.idle": "2025-05-21T08:04:02.803216Z",
     "shell.execute_reply": "2025-05-21T08:04:02.802238Z",
     "shell.execute_reply.started": "2025-05-21T08:04:02.797257Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant. Summarize the tool results in simple, natural language. \"\n",
    "        \"Avoid verbose introductions. Just clearly state what was computed.\"\n",
    "    ),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"Tool results:\\n{results}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "summarize_chain = summarize_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d385b5fc-99cf-48f1-8adb-6bfae1eb2a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:04:03.466743Z",
     "iopub.status.busy": "2025-05-21T08:04:03.465720Z",
     "iopub.status.idle": "2025-05-21T08:04:03.474441Z",
     "shell.execute_reply": "2025-05-21T08:04:03.472635Z",
     "shell.execute_reply.started": "2025-05-21T08:04:03.466704Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# The full chain: parse → invoke → summarize\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | JsonOutputParser()\n",
    "    | RunnableLambda(run_tool_calls)\n",
    "    | RunnableLambda(lambda state: summarize_chain.invoke({\"results\": state}))\n",
    "    | RunnableLambda(lambda x: x.content if hasattr(x, \"content\") else x)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b11459e8-f4ce-4d0c-86e3-0ba657015a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:05:53.173760Z",
     "iopub.status.busy": "2025-05-21T08:05:53.172976Z",
     "iopub.status.idle": "2025-05-21T08:05:56.994788Z",
     "shell.execute_reply": "2025-05-21T08:05:56.992569Z",
     "shell.execute_reply.started": "2025-05-21T08:05:53.173693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'234 multiplied by 3 equals 702. \\n\\n293 plus 98 equals 391.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is 234 * 3 and 293 + 98\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
